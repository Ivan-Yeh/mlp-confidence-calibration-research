{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# llama_3.1 8B Instruct with Logits\n",
    "\n",
    "This model could ben downloaded and deploy locally, despite its slow runtime. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivan/Documents/uni-projects/mlp-confidence-calibration-research/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from huggingface_hub import snapshot_download, login\n",
    "import numpy as np\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "login(token=os.environ[\"HF_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 16 files: 100%|██████████| 16/16 [00:00<00:00, 90810.37it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.68s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model\n",
    "local_dir = snapshot_download(repo_id=\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "model = LlamaForCausalLM.from_pretrained(local_dir, torch_dtype=torch.float16, low_cpu_mem_usage=True)\n",
    "tokeniser = AutoTokenizer.from_pretrained(local_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_tokeniser_with_sgc(message_lst: list[dict], tokeniser: AutoTokenizer, model: LlamaForCausalLM, max_new_tokens = 5) -> tuple:\n",
    "    flat_msg_list = []\n",
    "    for x in range(len(message_lst)): flat_msg_list += [{\"role\":k , \"content\": v} for k, v in message_lst[x].items()]\n",
    "    inputs = tokeniser(tokeniser.apply_chat_template(flat_msg_list, tokenize=False, add_generation_prompt=True), return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs['input_ids'], \n",
    "            max_new_tokens=max_new_tokens, \n",
    "            return_dict_in_generate=True, \n",
    "            output_logits=True,\n",
    "            output_scores=True,\n",
    "            top_p =0.9\n",
    "        )\n",
    "    return \"\".join(tokeniser.batch_decode(outputs.sequences[:, inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True)), float(np.exp(model.compute_transition_scores(outputs.sequences, outputs.scores, normalize_logits=True).numpy(force=True)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"Here's a list of the top 10 richest people in the world, based on the Forbes Billionaires List 2023:\\n\\n1. **Bernard Arnault - Net Worth: $230 billion**\\n   - Nationality: French\\n   - Occupation: Business magnate, Investor\\n   - Companies: LVMH (Moët Hennessy Louis Vuitton), Christian Dior, and others\\n\\n2. **Elon Musk - Net Worth: $190 billion**\\n   - Nationality: South African-American\\n   - Occupation: Entrepreneur, Business magnate\\n   - Companies: SpaceX, Tesla, Neuralink, and others\\n\\n3. **Jeff Bezos - Net Worth: $140 billion**\\n   - Nationality: American\\n   - Occupation: Entrepreneur, Business magnate\\n   - Companies: Amazon, Blue Origin\\n\\n4. **Bill Gates - Net Worth: $130 billion**\\n   - Nationality: American\\n   - Occupation: Business magnate, Philanthropist\\n   - Companies: Microsoft\\n\\n5. **Warren Buffett - Net Worth: $120 billion**\\n   - Nationality: American\\n   - Occupation: Investor, Business magnate\\n   - Companies: Berkshire Hathaway\\n\\n6. **Mark Zuckerberg - Net\",\n",
       " 0.9486111402511597)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_tokeniser_with_sgc([{\"user\": \"Who are the top riches people?\"}], tokeniser, model, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# msgs = [{\"user\": \"What is the most populated city in Australia?\"}, {\"system\": \"provide the answer as concisely as possible\"}]\n",
    "# multi_response = [response_tokeniser_with_sgc(msgs, tokeniser, model) for _ in range(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 0.5671795555608957),\n",
       " ('B', 0.006688037935689839),\n",
       " ('A', 0.32312966452742575),\n",
       " ('B', 0.8913660505211838),\n",
       " ('D', 0.023431141726125593),\n",
       " ('A', 0.3762705809561574),\n",
       " ('B', 0.7751518757390848),\n",
       " ('A', 0.29307948853273835),\n",
       " ('A', 0.44219249879984657),\n",
       " ('C', 0.6566782698658681),\n",
       " ('A', 0.6275072407590258),\n",
       " ('D', 0.17891707302661397),\n",
       " ('A', 0.7386071668341867),\n",
       " ('A', 0.4469239622093574),\n",
       " ('A', 0.7052241339770617),\n",
       " ('D', 0.12138475609063626),\n",
       " ('A', 0.2648679930555855),\n",
       " ('A', 0.7708806776946763),\n",
       " ('A', 0.40559243009857493),\n",
       " ('A', 0.3923507461217316),\n",
       " ('A', 0.5676950431328948),\n",
       " ('A', 0.9653199999268453),\n",
       " ('C', 0.9459039770411337),\n",
       " ('C', 0.8934748058898486),\n",
       " ('A', 0.8209174345364296),\n",
       " ('A', 0.4195759173233674),\n",
       " ('A', 0.6251506958176762),\n",
       " ('A', 0.2397868251522951),\n",
       " ('B', 0.7699579218427463),\n",
       " ('A', 0.6657001051039136),\n",
       " ('A', 0.9231818101195042),\n",
       " ('A', 0.9335733020135215),\n",
       " ('C', 0.2195753993282189),\n",
       " ('A', 0.12710028826051967),\n",
       " ('A', 0.9892971917144789),\n",
       " ('C', 0.9448898962008593),\n",
       " ('A', 0.7880211050416712),\n",
       " ('A', 0.14796577117255516),\n",
       " ('A', 0.20241262953326122),\n",
       " ('A', 0.6948216333417728),\n",
       " ('A', 0.15597197330977475),\n",
       " ('A', 0.9390955561283044),\n",
       " ('A', 0.35060296407767644),\n",
       " ('B', 0.6078218655664089),\n",
       " ('A', 0.8807707179493832),\n",
       " ('A', 0.7183686850529942),\n",
       " ('B', 0.4352475086742654),\n",
       " ('A', 0.01976011686298984),\n",
       " ('A', 0.035130875368668324),\n",
       " ('A', 0.6314866387878493)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multi_response = list(zip(np.random.default_rng().choice([\"A\", \"B\", \"C\", \"D\"], 50, p=[0.7, 0.1, 0.1, 0.1]).tolist(), (np.random.uniform(0, 1, 50)).tolist()))\n",
    "# multi_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_semantic_clusters(multi_response):\n",
    "    lnll_lst = [(x)[1] for x in multi_response]\n",
    "    response_list = [x[0] for x in multi_response]\n",
    "    distance_threshold = 0.3\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    "    embeddings = SentenceTransformer(model_name).encode(response_list)\n",
    "    clustering = AgglomerativeClustering(n_clusters=None, distance_threshold=distance_threshold, metric=\"cosine\", linkage=\"average\")\n",
    "    labels = clustering.fit_predict(embeddings)\n",
    "    return response_list, lnll_lst, labels\n",
    "\n",
    "def get_mcq_clusters(multi_response):\n",
    "    lnll_lst = [(x)[1] for x in multi_response]\n",
    "    response_list = [x[0] for x in multi_response]\n",
    "    choice_map = dict().setdefault(0)\n",
    "    choice_map = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'a': 1, 'b': 2, 'c': 3, 'd': 4}\n",
    "    labels = [choice_map[c] for c in response_list]\n",
    "    return response_list, lnll_lst, labels\n",
    "\n",
    "response_list, lnll_lst, labels = get_mcq_clusters(multi_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Single Generation Confidence (SGC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_generation_confidence(lnll_lst, response_list, labels):\n",
    "    return response_list[0], lnll_lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A', 0.5671795555608957)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_generation_confidence(lnll_lst, response_list, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "# 2. Empirical Semantic Confidence (E-SC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the $m$ responses grouped into $k$ clusters, we select the final output by identifying the most confident cluster $C^*$ and choosing the response within it with the highest $\\text{LN-LL: } y^*= \\text{argmax}_{y∈C^*}\\bar{l}(y |x).$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_semantic_confidence(lnll_lst, response_list, labels):\n",
    "    counts = Counter(labels)\n",
    "    opt_cluster, opt_conf = max([(int(cluster_id), count/sum(counts.values())) for cluster_id, count in counts.items()], key=lambda x: x[1])\n",
    "    optimal_response = max([(response_list[i], lnll_lst[i]) for i, label in enumerate(labels) if label == opt_cluster], key=lambda x: x[1])[0]\n",
    "    return optimal_response, opt_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A', 0.72)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empirical_semantic_confidence(lnll_lst, response_list, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Likelihood-based Semantic Confidence (L-SC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_based_semantic_confidence(lnll_lst, response_list, labels):\n",
    "    clustered = []\n",
    "    # for each cluster calculat the following:\n",
    "    for c in np.unique(labels):\n",
    "        sum_ci = sum([lnll_lst[i] for i in range(len(lnll_lst)) if labels[i] == c]) # s(Ci | x) = sum(LN-LL)\n",
    "        clustered.append((int(c), sum_ci))\n",
    "    total_lsc = sum([x[1] for x in clustered])\n",
    "    lsc = [(c[0], c[1] / total_lsc) for c in clustered]\n",
    "    \n",
    "    opt_cluster, opt_conf = max(lsc, key=lambda x: x[1])\n",
    "    optimal_response = max([(response_list[i], lnll_lst[i]) for i, label in enumerate(labels) if label == opt_cluster], key=lambda x: x[1])[0]\n",
    "\n",
    "    return optimal_response, opt_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A', 0.7198496955065203)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood_based_semantic_confidence(lnll_lst, response_list, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Mean Likelihood-based Semantic Confidence (ML-SC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_likelihood_based_semantic_confidence(lnll_lst, response_list, labels):\n",
    "    clustered = []\n",
    "    # for each cluster calculate s_bar(Ci | x):\n",
    "    for c in np.unique(labels):\n",
    "        sum_ci = sum([lnll_lst[i] for i in range(len(lnll_lst)) if labels[i] == c]) # s_bar(Ci | x) = sum(LN-LL) in cluster Ci\n",
    "        clustered.append((int(c), sum_ci / Counter(labels)[c])) # s_bar(Ci | x) = sum(LN-LL) / count(Ci)\n",
    "    total_mlsc = sum([x[1] for x in clustered])\n",
    "    mlsc = [(c[0], c[1] / total_mlsc) for c in clustered]\n",
    "    \n",
    "    opt_cluster, opt_conf = max(mlsc, key=lambda x: x[1])\n",
    "    optimal_response = max([(response_list[i], lnll_lst[i]) for i, label in enumerate(labels) if label == opt_cluster], key=lambda x: x[1])[0]\n",
    "\n",
    "    return optimal_response, opt_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C', 0.3746192061428716)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_likelihood_based_semantic_confidence(lnll_lst, response_list, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Bayesian Semantic Confidence (B-SC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_semantic_confidence(lnll_lst, response_list, labels):\n",
    "    clustered = []\n",
    "    for c in np.unique(labels):\n",
    "        pi = Counter(labels)[c] / len(labels) # pi = count(Ci) / count\n",
    "        joint_lnll = np.prod([lnll_lst[i] for i in range(len(lnll_lst)) if labels[i] == c]) # joint lnll = ∏(LN-LL) in cluster Ci\n",
    "        clustered.append((int(c), joint_lnll * pi)) # joint_lnll * pi\n",
    "    \n",
    "    total_bsc = sum([x[1] for x in clustered])\n",
    "    bsc = [(c[0], float(c[1] / total_bsc)) for c in clustered]\n",
    "\n",
    "    opt_cluster, opt_conf = max(bsc, key=lambda x: x[1])\n",
    "    optimal_response = max([(response_list[i], lnll_lst[i]) for i, label in enumerate(labels) if label == opt_cluster], key=lambda x: x[1])[0]\n",
    "\n",
    "    return optimal_response, opt_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C', 0.987692041934822)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesian_semantic_confidence(lnll_lst, response_list, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
